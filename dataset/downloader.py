import pandas as pd
import numpy as np
import requests
import time
import os
import json
from datetime import datetime, timedelta
import logging
import sys
import io
import ccxt

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ğŸ”· Ø±ÙØ¹ Ù…Ø´Ú©Ù„Ø§Øª Ø´Ø¨Ú©Ù‡ Ùˆ Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# Ø±ÙØ¹ Ù…Ø´Ú©Ù„ Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø± ÙˆÛŒÙ†Ø¯ÙˆØ²
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø´Ø¨Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ
socket.setdefaulttimeout(60)  # Ø§ÙØ²Ø§ÛŒØ´ Ø²Ù…Ø§Ù† ØªØ§ÛŒÙ…â€ŒØ§ÙˆØª

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ğŸ”· Ú©Ù„Ø§Ø³ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

class IranianRealDataCollector:
    def __init__(self, output_dir="iranian_real_data"):
        self.output_dir = output_dir
        self.metadata = {
            'created_at': datetime.now().isoformat(),
            'sources': {},
            'collection_stats': {
                'successful_symbols': 0,
                'failed_symbols': 0,
                'total_candles': 0
            }
        }
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª APIÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ Ø¯Ø± Ø§ÛŒØ±Ø§Ù†
        self.exchanges = {
            'kucoin': {
                'instance': ccxt.kucoin(),
                'rate_limit': 2.0,
                'enabled': True
            },
            'coinex': {
                'instance': ccxt.coinex(),
                'rate_limit': 2.5,
                'enabled': True
            },
            'nobitex': {
                'instance': ccxt.nobitex(),
                'rate_limit': 3.0,
                'enabled': False  # Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ API key Ø¯Ø§Ø±Ø¯
            },
            'wallex': {
                'instance': ccxt.wallex(),
                'rate_limit': 3.0,
                'enabled': False  # Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ API key Ø¯Ø§Ø±Ø¯
            }
        }
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ
        self._create_directories()
    
    def _create_directories(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø§Ø®ØªØ§Ø± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯"""
        directories = [
            f"{self.output_dir}/crypto",
            f"{self.output_dir}/stocks",
            f"{self.output_dir}/forex",
            f"{self.output_dir}/metadata"
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
            logging.info(f"âœ… Ù¾ÙˆØ´Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {directory}")
    
    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    # ğŸ”· Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ
    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

    def fetch_crypto_data(self, symbol, timeframe='4h', days=730):
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³"""
        logging.info(f"\nğŸ”„ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} ({timeframe})")
        logging.info("ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ ØªÙ„Ø§Ø´ Ø¨Ø§ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ Ø¯Ø± Ø§ÛŒØ±Ø§Ù†...")
        
        all_data = []
        successful_exchange = None
        
        # ØªÙ„Ø§Ø´ Ø¨Ø§ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ù‡ ØªØ±ØªÛŒØ¨ Ø§ÙˆÙ„ÙˆÛŒØª
        for exchange_name, exchange_config in self.exchanges.items():
            if not exchange_config['enabled']:
                continue
                
            try:
                logging.info(f"   ğŸ“¥ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø§Ø² {exchange_name}...")
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ§ÛŒÙ…â€ŒØ§Ø³ØªÙ…Ù¾â€ŒÙ‡Ø§
                end_time = datetime.now()
                start_time = end_time - timedelta(days=days)
                since = int(start_time.timestamp() * 1000)
                
                # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
                ohlcv = exchange_config['instance'].fetch_ohlcv(
                    symbol,
                    timeframe,
                    since=since,
                    limit=10000
                )
                
                if ohlcv and len(ohlcv) > 100:
                    all_data = ohlcv
                    successful_exchange = exchange_name
                    logging.info(f"   âœ… {exchange_name}: {len(ohlcv)} Ú©Ù†Ø¯Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
                    break
                
                time.sleep(exchange_config['rate_limit'])
                
            except Exception as e:
                logging.warning(f"   âš ï¸ {exchange_name} Ø®Ø·Ø§: {str(e)}")
                time.sleep(exchange_config['rate_limit'])
                continue
        
        if not all_
            logging.error(f"âŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯")
            return None
        
        # Ø§ÛŒØ¬Ø§Ø¯ DataFrame
        df = pd.DataFrame(all_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df['symbol'] = symbol
        
        logging.info(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ {symbol} Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯:")
        logging.info(f"   - Ù…Ù†Ø¨Ø¹: {successful_exchange}")
        logging.info(f"   - ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§: {len(df):,}")
        logging.info(f"   - Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {df['timestamp'].min()} ØªØ§ {df['timestamp'].max()}")
        
        return df
    
    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    # ğŸ”· Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ
    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

    def save_real_data(self, df, symbol, market_type, source):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø¯Ø± ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯"""
        try:
            # Ø³Ø§Ø®Øª Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø§ÛŒÙ…Ù†
            safe_symbol = symbol.replace('/', '_').replace(' ', '_')
            timestamp = datetime.now().strftime('%Y%m%d')
            base_filename = f"{safe_symbol}_{timestamp}"
            
            # Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ
            market_dir = {
                'crypto': f"{self.output_dir}/crypto",
                'stocks': f"{self.output_dir}/stocks",
                'forex': f"{self.output_dir}/forex"
            }.get(market_type, f"{self.output_dir}/other")
            
            # 1. Ø°Ø®ÛŒØ±Ù‡ Parquet
            parquet_path = f"{market_dir}/{base_filename}.parquet"
            df.to_parquet(parquet_path, compression='snappy', index=False)
            
            # 2. Ø°Ø®ÛŒØ±Ù‡ CSV
            csv_path = f"{market_dir}/{base_filename}.csv"
            df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ØªØ§Ø¯ÛŒØªØ§
            file_size_mb = os.path.getsize(parquet_path) / (1024 * 1024)
            self.metadata['sources'][symbol] = {
                'exchange': source,
                'market_type': market_type,
                'parquet_path': parquet_path,
                'csv_path': csv_path,
                'file_size_mb': round(file_size_mb, 2),
                'candle_count': len(df),
                'time_range': {
                    'start': df['timestamp'].min().isoformat(),
                    'end': df['timestamp'].max().isoformat()
                }
            }
            
            logging.info(f"ğŸ’¾ {symbol} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯:")
            logging.info(f"   - Parquet: {parquet_path} ({file_size_mb:.2f} MB)")
            logging.info(f"   - CSV: {csv_path}")
            logging.info(f"   - Ù…Ù†Ø¨Ø¹: {source}")
            
            return True
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ {symbol}: {str(e)}")
            return False
    
    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    # ğŸ”· Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ú©Ø§Ù…Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

    def collect_all_data(self):
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ Ø¯Ø± Ø§ÛŒØ±Ø§Ù†"""
        logging.info("=" * 80)
        logging.info("ğŸš€ Ø´Ø±ÙˆØ¹ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ Ø¯Ø± Ø§ÛŒØ±Ø§Ù†")
        logging.info("âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² KuCoin Ùˆ CoinEx Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ù†Ø§Ø¨Ø¹ Ø§ØµÙ„ÛŒ")
        logging.info("âœ… Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ VPN ÛŒØ§ Ø¯ÙˆØ± Ø²Ø¯Ù† Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§")
        logging.info("=" * 80)
        
        # Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ
        SYMBOLS_CONFIG = {
            'crypto': [
                'BTC/USDT',
                'ETH/USDT', 
                'SOL/USDT',
                'BNB/USDT',
                'ADA/USDT',
                'XRP/USDT'
            ]
        }
        
        for market_type, symbols in SYMBOLS_CONFIG.items():
            logging.info(f"\n{'='*60}")
            logging.info(f"ğŸ“ˆ Ø¨Ø§Ø²Ø§Ø±: {market_type.upper()}")
            logging.info(f"{'='*60}")
            
            for symbol in symbols:
                try:
                    logging.info(f"\nğŸ” Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù…Ø§Ø¯: {symbol}")
                    
                    if market_type == 'crypto':
                        df = self.fetch_crypto_data(symbol, timeframe='4h', days=730)
                    else:
                        logging.warning(f"âš ï¸ Ù†ÙˆØ¹ Ø¨Ø§Ø²Ø§Ø± Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ø´Ø¯Ù‡: {market_type}")
                        continue
                    
                    if df is not None and not df.empty:
                        if self.save_real_data(df, symbol, market_type, 'kucoin_or_coinex'):
                            self.metadata['collection_stats']['successful_symbols'] += 1
                            self.metadata['collection_stats']['total_candles'] += len(df)
                    else:
                        self.metadata['collection_stats']['failed_symbols'] += 1
                        logging.error(f"âŒ Ø´Ú©Ø³Øª Ø¯Ø± Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {symbol}")
                    
                    # ØªØ£Ø®ÛŒØ± Ø¨ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø­Ø¯ÙˆØ¯ÛŒØª
                    time.sleep(2)
                    
                except KeyboardInterrupt:
                    logging.info("\nğŸ›‘ Ø¹Ù…Ù„ÛŒØ§Øª ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯.")
                    return
                except Exception as e:
                    logging.error(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± {symbol}: {str(e)}")
                    self.metadata['collection_stats']['failed_symbols'] += 1
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù…ØªØ§Ø¯ÛŒØªØ§
        self._save_metadata()
        
        logging.info(f"\n{'='*80}")
        logging.info("ğŸ‰ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯!")
        logging.info(f"   - Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…ÙˆÙÙ‚: {self.metadata['collection_stats']['successful_symbols']}")
        logging.info(f"   - Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø´Ú©Ø³Øªâ€ŒØ®ÙˆØ±Ø¯Ù‡: {self.metadata['collection_stats']['failed_symbols']}")
        logging.info(f"   - Ú©Ù„ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§: {self.metadata['collection_stats']['total_candles']:,}")
        logging.info(f"   - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø±: {os.path.abspath(self.output_dir)}")
        logging.info(f"{'='*80}")
    
    def _save_metadata(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ù…ØªØ§Ø¯ÛŒØªØ§ Ùˆ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§"""
        try:
            metadata_path = f"{self.output_dir}/metadata/dataset_metadata.json"
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(self.metadata, f, indent=2, ensure_ascii=False)
            
            logging.info(f"ğŸ“„ Ù…ØªØ§Ø¯ÛŒØªØ§ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {metadata_path}")
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù…ØªØ§Ø¯ÛŒØªØ§: {str(e)}")

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# â–¶ï¸ Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø¯
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

if __name__ == "__main__":
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('real_data_collection.log', encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    print("=" * 80)
    print("=== Ø³ÛŒØ³ØªÙ… Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ ===")
    print("âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² KuCoin Ùˆ CoinEx Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ù†Ø§Ø¨Ø¹ Ø§ØµÙ„ÛŒ")
    print("âœ… Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ VPN ÛŒØ§ Ø¯ÙˆØ± Ø²Ø¯Ù† Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§")
    print("âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ùˆ Ú©ÛŒÙÛŒØªâ€ŒØ¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ")
    print("=" * 80)
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ø§Ø¬Ø±Ø§ÛŒ Ø³ÛŒØ³ØªÙ…
    collector = IranianRealDataCollector(output_dir="iranian_real_data")
    collector.collect_all_data()
    
    print("\nâœ… Ø³ÛŒØ³ØªÙ… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø¬Ø±Ø§ Ø´Ø¯!")
    print("ğŸ’¡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ§Ù†Ø¯:")
    print("   - Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¯Ø± Google Colab Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯")
    print("   - Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ LSTM Ùˆ Transformer Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯")
    print("   - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø¯Ù‚ÛŒÙ‚ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯")