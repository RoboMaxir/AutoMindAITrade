import pandas as pd
import numpy as np
import time
import os
from datetime import datetime
from ta.trend import EMAIndicator
from ta.momentum import RSIIndicator
from ta.volatility import AverageTrueRange
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ğŸ”· Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ (Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§ÛŒÙ†ØªØ±Ù†Øª)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

def load_local_data(symbol="BTC/USDT", data_dir="historical_data"):
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡"""
    filename = f"{symbol.replace('/', '_')}_4h_3years.csv"
    filepath = os.path.join(data_dir, filename)
    
    if not os.path.exists(filepath):
        raise FileNotFoundError(f"ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯: {filepath}")
    
    print(f"ğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø²: {filepath}")
    df = pd.read_csv(filepath)
    
    # ØªØ¨Ø¯ÛŒÙ„ timestamp Ø¨Ù‡ datetime
    if 'timestamp' in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    print(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯:")
    print(f"   - ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§: {len(df):,}")
    print(f"   - Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {df['timestamp'].min()} ØªØ§ {df['timestamp'].max()}")
    print(f"   - Ø¢Ø®Ø±ÛŒÙ† Ù‚ÛŒÙ…Øª: {df['close'].iloc[-1]:,.2f} USDT")
    
    return df

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ğŸ”· Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

def preprocess_data(df):
    """Ø§ÛŒØ¬Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ LSTM"""
    print("\nğŸ”§ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù¾ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªØºÛŒÛŒØ± Ø¯Ø§Ø¯Ù‡ Ø§ØµÙ„ÛŒ
    data = df.copy()
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
    data['rsi'] = RSIIndicator(data['close'], window=14).rsi()
    data['ema20'] = EMAIndicator(data['close'], window=20).ema_indicator()
    data['ema50'] = EMAIndicator(data['close'], window=50).ema_indicator()
    data['macd'] = (EMAIndicator(data['close'], window=12).ema_indicator() - 
                   EMAIndicator(data['close'], window=26).ema_indicator())
    data['atr'] = AverageTrueRange(data['high'], data['low'], data['close'], window=14).average_true_range()
    data['volume_ma'] = data['volume'].rolling(20).mean()
    data['volume_ratio'] = data['volume'] / data['volume_ma']
    data['return'] = data['close'].pct_change()
    
    # Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙÙ‚ÙˆØ¯Ù‡
    data = data.dropna()
    
    print(f"âœ… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù†Ø¯:")
    print(f"   - ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÙ‡â€ŒØ´Ø¯Ù‡: RSI, EMA20/50, MACD, ATR, Volume Ratio")
    print(f"   - ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ: {len(data):,}")
    
    return data

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ğŸ”· Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ LSTM
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

def prepare_lstm_data(data, lookback=60, predict_horizon=5):
    """
    Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ LSTM
    lookback: ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
    predict_horizon: Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú†Ù†Ø¯ Ú©Ù†Ø¯Ù„ Ø¢ÛŒÙ†Ø¯Ù‡
    """
    print(f"\nğŸ§  Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ LSTM (lookback={lookback}, horizon={predict_horizon})...")
    
    # Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ
    feature_cols = ['close', 'rsi', 'ema20', 'ema50', 'macd', 'atr', 'volume_ratio', 'return']
    
    # Ù…Ù‚ÛŒØ§Ø³â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data[feature_cols])
    
    X, y = [], []
    
    for i in range(lookback, len(scaled_data) - predict_horizon):
        X.append(scaled_data[i-lookback:i])
        y.append(scaled_data[i + predict_horizon][0])  # ÙÙ‚Ø· Ù‚ÛŒÙ…Øª close
    
    X = np.array(X)
    y = np.array(y)
    
    print(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯:")
    print(f"   - Ø´Ú©Ù„ X: {X.shape}")
    print(f"   - Ø´Ú©Ù„ y: {y.shape}")
    
    return X, y, scaler

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ğŸ”· Ø³Ø§Ø®Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ LSTM
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

def build_and_train_lstm(X, y, symbol="BTC/USDT"):
    """Ø³Ø§Ø®Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ LSTM Ø¨Ø§ Early Stopping"""
    print(f"\nâš¡ï¸ Ø³Ø§Ø®Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ LSTM Ø¨Ø±Ø§ÛŒ {symbol}...")
    
    # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
    split = int(0.8 * len(X))
    X_train, X_val = X[:split], X[split:]
    y_train, y_val = y[:split], y[split:]
    
    print(f"ğŸ“Š ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:")
    print(f"   - Ø¢Ù…ÙˆØ²Ø´: {len(X_train):,} Ù†Ù…ÙˆÙ†Ù‡")
    print(f"   - Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ: {len(X_val):,} Ù†Ù…ÙˆÙ†Ù‡")
    
    # Ø³Ø§Ø®Øª Ù…Ø¯Ù„
    model = Sequential([
        LSTM(128, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),
        Dropout(0.2),
        LSTM(64),
        Dropout(0.2),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    
    # Callbacks Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ùˆ ØªÙˆÙ‚Ù Ø²ÙˆØ¯Ù‡Ù†Ú¯Ø§Ù…
    callbacks = [
        EarlyStopping(patience=15, restore_best_weights=True, verbose=1),
        ModelCheckpoint(f'model_{symbol.replace("/", "_")}_best.h5', save_best_only=True, verbose=1)
    ]
    
    # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=100,
        batch_size=32,
        callbacks=callbacks,
        verbose=1
    )
    
    # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
    train_loss, train_mae = model.evaluate(X_train, y_train, verbose=0)
    val_loss, val_mae = model.evaluate(X_val, y_val, verbose=0)
    
    print(f"\nâœ… Ø¢Ù…ÙˆØ²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯!")
    print(f"   - Ø®Ø·Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ (MAE): {train_mae:.4f}")
    print(f"   - Ø®Ø·Ø§ÛŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ (MAE): {val_mae:.4f}")
    
    return model, history

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ğŸ”· ØªØ±Ø³ÛŒÙ… Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

def plot_training_history(history, symbol="BTC/USDT"):
    """ØªØ±Ø³ÛŒÙ… Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯"""
    plt.figure(figsize=(12, 6))
    
    # Ù†Ù…ÙˆØ¯Ø§Ø± loss
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Ø¢Ù…ÙˆØ²Ø´')
    plt.plot(history.history['val_loss'], label='Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ')
    plt.title(f'Loss - {symbol}')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    
    # Ù†Ù…ÙˆØ¯Ø§Ø± MAE
    plt.subplot(1, 2, 2)
    plt.plot(history.history['mae'], label='Ø¢Ù…ÙˆØ²Ø´')
    plt.plot(history.history['val_mae'], label='Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ')
    plt.title(f'MAE - {symbol}')
    plt.xlabel('Epoch')
    plt.ylabel('MAE')
    plt.legend()
    
    plt.tight_layout()
    plot_path = f'training_history_{symbol.replace("/", "_")}.png'
    plt.savefig(plot_path)
    plt.close()
    
    print(f"ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯: {plot_path}")
    return plot_path

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# â–¶ï¸ Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø¢Ù…ÙˆØ²Ø´
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

if __name__ == "__main__":
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    SYMBOL = "BTC/USDT"
    DATA_DIR = "historical_data"
    
    print(f"{'='*80}")
    print("ğŸš€ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ±ÛŒØ¯ Ø®ÙˆØ¯Ú©Ø§Ø±")
    print(f"   - Ù†Ù…Ø§Ø¯: {SYMBOL}")
    print(f"   - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {DATA_DIR}")
    print(f"{'='*80}")
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
    os.makedirs("models", exist_ok=True)
    os.makedirs("plots", exist_ok=True)
    
    try:
        # 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        df = load_local_data(SYMBOL, DATA_DIR)
        
        # 2. Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´
        processed_data = preprocess_data(df)
        
        # 3. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ LSTM
        X, y, scaler = prepare_lstm_data(processed_data)
        
        # 4. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
        model, history = build_and_train_lstm(X, y, SYMBOL)
        
        # 5. ØªØ±Ø³ÛŒÙ… Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§
        plot_path = plot_training_history(history, SYMBOL)
        
        # 6. Ø°Ø®ÛŒØ±Ù‡ Ø§Ø³Ú©ÛŒÙ„Ø±
        import pickle
        scaler_path = f'models/scaler_{SYMBOL.replace("/", "_")}.pkl'
        with open(scaler_path, 'wb') as f:
            pickle.dump(scaler, f)
        print(f"ğŸ’¾ Ø§Ø³Ú©ÛŒÙ„Ø± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {scaler_path}")
        
        # 7. Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ
        print(f"\n{'='*80}")
        print("ğŸ‰ Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯!")
        print(f"   - Ù…Ø¯Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: model_{SYMBOL.replace('/', '_')}_best.h5")
        print(f"   - Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§: {plot_path}")
        print(f"   - Ø§Ø³Ú©ÛŒÙ„Ø±: {scaler_path}")
        print(f"{'='*80}")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ÛŒ Ú©Ø§Ù…Ù„: {str(e)}")
        print("ğŸ’¡ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:")
        print("   - Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± Ù¾ÙˆØ´Ù‡ historical_data")
        print("   - Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²: pip install tensorflow ta scikit-learn matplotlib")